# services/ia_correccion_service.py
import requests
import os
import json
import re
import threading
from django.conf import settings

class IACorreccionService:
    def __init__(self):
        self.api_url = "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large"
        self.api_token = os.getenv('HUGGINGFACE_API_TOKEN', 'hf_tu_token_aqui')
    
    def corregir_evaluacion_completa(self, examen_alumno_id):
        """Corrige autom√°ticamente todas las respuestas de una evaluaci√≥n"""
        try:
            from .models import ExamenAlumno, RespuestaAlumno
            
            # Obtener el examen_alumno con sus respuestas
            examen_alumno = ExamenAlumno.objects.get(id=examen_alumno_id)
            respuestas = RespuestaAlumno.objects.filter(
                examen_alumno=examen_alumno
            ).select_related('pregunta')
            
            puntaje_total = 0
            puntaje_maximo_total = 0
            correcciones_realizadas = 0
            
            print(f"üîç Iniciando correcci√≥n autom√°tica para examen_alumno {examen_alumno_id}")
            print(f"üìù Encontradas {respuestas.count()} respuestas para corregir")
            
            # Corregir cada respuesta individual
            for respuesta in respuestas:
                print(f"üìã Corrigiendo pregunta: {respuesta.pregunta.enunciado[:50]}...")
                
                correccion = self.corregir_respuesta(
                    respuesta.pregunta.enunciado,
                    respuesta.respuesta,
                    respuesta.pregunta.puntaje
                )
                
                # Actualizar la respuesta con los resultados de la IA
                respuesta.puntaje_obtenido = correccion['puntaje']
                respuesta.retroalimentacion = correccion['justificacion']
                respuesta.save()
                
                puntaje_total += correccion['puntaje']
                puntaje_maximo_total += float(respuesta.pregunta.puntaje)
                correcciones_realizadas += 1
                
                print(f"‚úÖ Pregunta {correcciones_realizadas} corregida: {correccion['puntaje']}/{respuesta.pregunta.puntaje}")
            
            # Calcular calificaci√≥n final (0-20)
            if puntaje_maximo_total > 0:
                calificacion_final = (puntaje_total / puntaje_maximo_total) * 20
            else:
                calificacion_final = 0
            
            # Actualizar el examen_alumno
            examen_alumno.calificacion_final = round(calificacion_final, 2)
            examen_alumno.retroalimentacion = f"Corregido autom√°ticamente por IA. {correcciones_realizadas}/{respuestas.count()} preguntas procesadas."
            examen_alumno.estado = 'corregido'
            examen_alumno.save()
            
            print(f"üéØ Correcci√≥n completada. Calificaci√≥n final: {calificacion_final}/20")
            
            return {
                'success': True,
                'calificacion_final': calificacion_final,
                'puntaje_total': puntaje_total,
                'puntaje_maximo': puntaje_maximo_total,
                'preguntas_corregidas': correcciones_realizadas
            }
            
        except Exception as e:
            print(f"‚ùå Error en correcci√≥n autom√°tica: {e}")
            return {'success': False, 'error': str(e)}
    
    def corregir_respuesta(self, enunciado, respuesta_alumno, puntaje_maximo):
        """Env√≠a respuesta a Hugging Face API para correcci√≥n"""
        
        prompt = self._construir_prompt(enunciado, respuesta_alumno, puntaje_maximo)
        
        try:
            headers = {"Authorization": f"Bearer {self.api_token}"}
            
            payload = {
                "inputs": prompt,
                "parameters": {
                    "max_new_tokens": 100,
                    "temperature": 0.3,
                    "do_sample": True,
                    "return_full_text": False
                }
            }
            
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                resultado = response.json()
                return self._procesar_respuesta_huggingface(resultado, puntaje_maximo, respuesta_alumno)
            else:
                print(f"‚ö†Ô∏è Error API Hugging Face: {response.status_code} - {response.text}")
                return self._fallback_correction(puntaje_maximo)
                
        except Exception as e:
            print(f"‚ùå Error en correcci√≥n IA: {e}")
            return self._fallback_correction(puntaje_maximo)
    
    def _construir_prompt(self, enunciado, respuesta_alumno, puntaje_maximo):
        """Construye el prompt para la IA"""
        
        return f"""
        Eres un profesor universitario corrigiendo evaluaciones de manera JUSTA y GENEROSA.
        
        CONTEXTO:
        - Pregunta: "{enunciado}"
        - Respuesta del estudiante: "{respuesta_alumno}"
        - Puntaje m√°ximo: {puntaje_maximo}
        
        INSTRUCCIONES ESPEC√çFICAS:
        1. Eval√∫a la respuesta considerando el ESFUERZO y la COHERENCIA
        2. S√© GENEROSO pero OBJETIVO en tu evaluaci√≥n
        3. Si la respuesta muestra comprensi√≥n b√°sica, otorga al menos el 50% del puntaje
        4. Si la respuesta es correcta pero incompleta, otorga entre 60-90%
        5. Solo da 0 si la respuesta est√° completamente vac√≠a o sin relaci√≥n alguna
        6. Proporciona una breve justificaci√≥n (lo que consideres necesario)
        7. No tengas miedo de poner calificaciones perfectas si cubre lo mas importante
        
        FORMATO DE RESPUESTA OBLIGATORIO:
        PUNTAJE|JUSTIFICACION_BREVE
        
        Ejemplo: 3.5|El estudiante demuestra comprensi√≥n b√°sica pero falta profundizar en X concepto porque (explicar).
        
        Tu evaluaci√≥n:
        """
    
    def _procesar_respuesta_huggingface(self, respuesta_api, puntaje_maximo, respuesta_alumno):
        """Procesa la respuesta de Hugging Face API"""
        try:
            # Extraer texto de la respuesta
            if isinstance(respuesta_api, list) and len(respuesta_api) > 0:
                texto_respuesta = respuesta_api[0].get('generated_text', '')
            else:
                texto_respuesta = str(respuesta_api)
            
            print(f"üì® Respuesta IA cruda: {texto_respuesta}")
            
            # Buscar el formato PUNTAJE|JUSTIFICACION
            if "|" in texto_respuesta:
                partes = texto_respuesta.split("|", 1)
                puntaje_str = partes[0].strip()
                justificacion = partes[1].strip() if len(partes) > 1 else "Evaluaci√≥n autom√°tica completada."
                
                # Extraer n√∫mero del puntaje
                numeros = re.findall(r"(\d+\.?\d*)", puntaje_str)
                if numeros:
                    puntaje = float(numeros[0])
                    # Asegurar que el puntaje no exceda el m√°ximo
                    puntaje = min(puntaje, float(puntaje_maximo))
                    # Asegurar que no sea negativo
                    puntaje = max(puntaje, 0)
                    
                    return {
                        'puntaje': round(puntaje, 2),
                        'justificacion': justificacion,
                        'fuente': 'huggingface_ia',
                        'respuesta_cruda': texto_respuesta
                    }
            
            # Fallback: an√°lisis sem√°ntico simple
            return self._analisis_fallback(respuesta_alumno, puntaje_maximo, texto_respuesta)
            
        except Exception as e:
            print(f"‚ùå Error procesando respuesta IA: {e}")
            return self._fallback_correction(puntaje_maximo)
    
    def _analisis_fallback(self, respuesta_alumno, puntaje_maximo, texto_ia):
        """An√°lisis de fallback cuando el formato no es el esperado"""
        try:
            # Puntaje basado en longitud y contenido b√°sico
            respuesta_limpia = respuesta_alumno.strip()
            longitud = len(respuesta_limpia)
            palabras = len(respuesta_limpia.split())
            
            # Puntaje base por esfuerzo
            if longitud == 0:
                puntaje_base = 0
                justificacion = "Respuesta vac√≠a. No se puede evaluar contenido."
            else:
                # Base por escribir algo + bonus por extensi√≥n
                puntaje_base = min(float(puntaje_maximo) * 0.4, 1.5)
                
                # Bonus por longitud (si es desarrollo)
                if palabras > 15:
                    puntaje_base += min(float(puntaje_maximo) * 0.3, 2.0)
                elif palabras > 5:
                    puntaje_base += min(float(puntaje_maximo) * 0.15, 1.0)
                
                justificacion = "Respuesta evaluada autom√°ticamente. Se consider√≥ el esfuerzo y extensi√≥n de la respuesta."
            
            return {
                'puntaje': round(puntaje_base, 2),
                'justificacion': justificacion,
                'fuente': 'fallback_analisis',
                'respuesta_cruda': texto_ia
            }
            
        except Exception as e:
            print(f"‚ùå Error en an√°lisis fallback: {e}")
            return self._fallback_correction(puntaje_maximo)
    
    def _fallback_correction(self, puntaje_maximo):
        """Correcci√≥n de fallback cuando todo falla"""
        return {
            'puntaje': round(float(puntaje_maximo) * 0.6, 2),
            'justificacion': 'Evaluaci√≥n autom√°tica completada con m√©todo de respaldo. Revisi√≥n docente recomendada.',
            'fuente': 'fallback_generico'
        }

def iniciar_correccion_automatica_async(examen_alumno_id):
    """Funci√≥n auxiliar para iniciar correcci√≥n en segundo plano"""
    def tarea_correccion():
        try:
            correccion_service = IACorreccionService()
            resultado = correccion_service.corregir_evaluacion_completa(examen_alumno_id)
            
            if resultado['success']:
                print(f"‚úÖ Correcci√≥n autom√°tica COMPLETADA para examen_alumno {examen_alumno_id}")
                print(f"üìä Calificaci√≥n final: {resultado['calificacion_final']}/20")
            else:
                print(f"‚ö†Ô∏è Correcci√≥n autom√°tica con ERRORES para examen_alumno {examen_alumno_id}")
                print(f"‚ùå Error: {resultado['error']}")
                
        except Exception as e:
            print(f"üí• Error cr√≠tico en correcci√≥n autom√°tica: {e}")
    
    thread = threading.Thread(target=tarea_correccion)
    thread.daemon = True
    thread.start()
    print(f"üöÄ Correcci√≥n autom√°tica INICIADA en segundo plano para examen_alumno {examen_alumno_id}")